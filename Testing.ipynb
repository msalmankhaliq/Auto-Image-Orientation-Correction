{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import imutils\n",
    "import h5py\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = \"model/trained\" #open saved model\n",
    "test_dataset = \"test_images/\" #open testing dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_names = db[\"label_names\"]\n",
    "#ln = [item.replace('Rotated/', '') for item in label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the label names (i.e., angles) from the HDF5 dataset\n",
    "db = h5py.File(\"HDF5file\")\n",
    "labelNames = [(angle) for angle in db[\"label_names\"][:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] sampling images...\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# grab the paths to the testing images and randomly sample them\n",
    "print(\"[INFO] sampling images...\")\n",
    "imagePaths = list(paths.list_images(test_dataset))\n",
    "imagePaths = np.random.choice(imagePaths, size=(1,), replace=False)\n",
    "print(len(imagePaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n"
     ]
    }
   ],
   "source": [
    "# load the VGG16 network\n",
    "print(\"[INFO] loading network...\")\n",
    "vgg = VGG16(weights=\"imagenet\", include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "# load the orientation model\n",
    "print(\"[INFO] loading model...\")\n",
    "model = pickle.loads(open(trained_model, \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "\t# load the image via OpenCV so we can manipulate it after\n",
    "\t# classification\n",
    "\torig = cv2.imread(imagePath)\n",
    "\n",
    "\t# load the input image using the Keras helper utility while\n",
    "\t# ensuring the image is resized to 224x224 pixels\n",
    "\timage = load_img(imagePath, target_size=(224, 224))\n",
    "\timage = img_to_array(image)\n",
    "\n",
    "\t# preprocess the image by (1) expanding the dimensions and (2)\n",
    "\t# subtracting the mean RGB pixel intensity from the ImageNet\n",
    "\t# dataset\n",
    "\timage = np.expand_dims(image, axis=0)\n",
    "\timage = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "\t# pass the image through the network to obtain the feature vector\n",
    "\tfeatures = vgg.predict(image)\n",
    "\tfeatures = features.reshape((features.shape[0], 512 * 7 * 7))\n",
    "\n",
    "\t# now that we have the CNN features, pass these through our\n",
    "\t# classifier to obtain the orientation predictions\n",
    "\tangle = model.predict(features)\n",
    "\tangle = labelNames[angle[0]]\n",
    "\n",
    "\t# now that we have the predicted orientation of the image we can\n",
    "\t# correct for it\n",
    "\trotated = imutils.rotate_bound(orig, 360 - int(angle[8:]))\n",
    "\n",
    "\t# display the original and corrected images\n",
    "\tcv2.imshow(\"Original\", orig)\n",
    "\tcv2.imshow(\"Corrected\", rotated)\n",
    "\tcv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
